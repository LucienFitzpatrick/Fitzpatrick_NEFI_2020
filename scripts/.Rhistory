#-----------------------------------------------------------------------------------------------------------------------------------#
library(rjags)
library(coda)
library(ecoforecastR)
path.doc <- ("../data_processed/fall/")
path.fig <- ("../data_processed/fall/figures")
#path.hub <- ("C:/Users/lucie/Documents/GitHub/NEFI/figures")
dat.npn <- read.csv(file.path(path.doc, "Arb_Fall_Phenology_data.csv"))
dat.2018 <- dat.npn[dat.npn$year == 2018,]
dat.2018 <- dat.2018[dat.2018$day_of_year <= 341,]
dat.npn <- dat.npn[dat.npn$year == 2019,]
dat.npn <- dat.npn[order(dat.npn$day_of_year),]
dat.npn$color.clean <- as.numeric(as.character(dat.npn$color.clean))
RandomWalk_binom = "
model{
#### Data Model
for(i in 1:n){
y[i] ~ dbern(x[time[i]])
}
#### Process Model
for(t in 2:nt){
z[t] ~ dnorm(x[t-1],tau_add)
x[t] <- min(0.999,max(0.0001,z[t]))
}
#### Priors
x[1] ~ dlnorm(x_ic,tau_ic)
tau_add ~ dgamma(a_add,r_add)
}
"
#dat.roll <- dat.roll[dat.roll$week < 48,]
data.new <- list(y = dat.npn$color.clean, n = length(dat.npn$color.clean), time = dat.npn$day_of_year-(min(dat.npn$day_of_year)-1), nt = 341-213,
a_add=100, r_add=1, x_ic = -100 , tau_ic = 1000)
j.model   <- jags.model (file = textConnection(RandomWalk_binom),
data = data.new,
n.chains = 3)
jags.out   <- coda.samples (model = j.model,
variable.names = c("x","tau_add"),
n.iter = 40000)
gelman.diag(jags.out)
#plot(jags.out)
#GBR <- gelman.plot(jags.out)
burnin = 30000                                ## determine convergence
jags.burn <- window(jags.out,start=burnin)
## remove burn-in
#plot(jags.burn)
#summary(jags.burn)## check diagnostics post burn-in
out <- as.matrix(jags.burn)
x.cols <- grep("^x",colnames(out)) ## grab all columns that start with the letter x
ci <- apply(out[,x.cols],2,quantile,c(0.025,0.5,0.975))
time <- 214:341
data_all = dat.npn[,c("day_of_year","color.clean")]
data_all = data_all[order(data_all$day_of_year),]
data_all$color.clean = as.numeric(as.character(data_all$color.clean))
data_all$day_of_year = as.numeric(as.character(data_all$day_of_year))
data_all_loess_10 <- loess(as.numeric(as.character(color.clean)) ~ as.numeric(as.character(day_of_year)), data=data_all, span=0.10) # 10% smoothing span
data_all_loess_10 <- predict(data_all_loess_10)
data_all_loess_30 <- loess(as.numeric(as.character(color.clean)) ~ as.numeric(as.character(day_of_year)), data=data_all, span=0.30) # 30% smoothing span
data_all_loess_30 <- predict(data_all_loess_30)
png(filename= file.path(path.fig, paste0("Daily_Oak_Collection_Model_CI.png")))
plot(time,ci[2,],ylim=c(0,1), xlim=c(210, 350),main = "Daily Oak Collection Model CI", ylab="Fall color")
ecoforecastR::ciEnvelope(time,ci[1,],ci[3,],col=ecoforecastR::col.alpha("lightBlue",0.75))
points(dat.npn$day_of_year, dat.npn$color.clean ,pch="+",cex=0.5)
lines(data_all_loess_10, x=data_all$day_of_year, col="red", lwd = 2)
lines(data_all_loess_30, x=data_all$day_of_year, col="blue", lwd = 2)
dev.off()
#This section is for defining a range for a 2018 hindcast
dat.2018$day_of_year <- as.numeric(as.character(dat.2018$day_of_year))
dat.2018$color.clean <- as.numeric(as.character(dat.2018$color.clean))
data_2018 <- list(y = dat.2018$color.clean, n = length(dat.2018$color.clean), time = dat.2018$day_of_year-(min(dat.2018$day_of_year)-1), nt = 341-213,
a_add=100, r_add=1, x_ic = -100, tau_ic = 1000)
#------------------------------------------------------------------------------------------#
#Here is where the 2018 forecast begins and things start getting tricky
#------------------------------------------------------------------------------------------#
#-------------------------------------#
#First is the forecast function that determines our uncertainty at each time point
#--------------------------------------#
#Number of monte Carlo iterations that will be used
Nmc = 10
#Set the Initial conditions using the parameters from your model
#IC <- rlnorm(Nmc, data$x_ic,(1/sqrt(data$tau_ic)))
#This if for 2018 hindcast testing
IC <- rlnorm(Nmc, data_2018$x_ic,(1/sqrt(data_2018$tau_ic)))
#### Forecast function
##` @param IC    Initial Conditions
##` @param Q     Process error (default = 0 for deterministic runs)
##` @param n     Size of Monte Carlo ensemble
NT = data_2018$nt
forecastx <- function(IC,Q,n=Nmc){
x <- z <- matrix(NA,n,NT)  ## storage
Xprev <- IC           ## initialize
for(t in 1:NT){
mu <- Xprev
z[,t] = rnorm(n,mu, Q)
x[,t] <- pmin(0.999,pmax(0.0001,z[,t]))
Xprev <- x[,t]                                  ## update IC
}
return(x)
}
param.mean <- apply(out,2,mean)
x.det_LOD <- forecastx(IC=mean(IC),
Q=mean((1/sqrt(out[,"tau_add"]))),  ## process error off
n=Nmc)
x.i_LOD <- forecastx(IC=IC,
Q=mean((1/sqrt(out[,"tau_add"]))),  ## process error off
n=Nmc)
s = seq(1, nrow(out), length=Nmc)
x.ip_LOD <- forecastx(IC=IC,
Q=1/sqrt(out[s,"tau_add"]),  ## process error off
n=Nmc)
det_ci_LOD <- apply(x.det_LOD,2,quantile,c(0.025,0.5,0.975))
i_ci_LOD <- apply(x.i_LOD,2,quantile,c(0.025,0.5,0.975))
ip_ci_LOD <- apply(x.ip_LOD,2,quantile,c(0.025,0.5,0.975))
library(rjags)
library(coda)
library(ecoforecastR)
path.doc <- ("../data_processed/fall/")
path.fig <- ("../data_processed/fall/figures")
#path.hub <- ("C:/Users/lucie/Documents/GitHub/NEFI/figures")
dat.npn <- read.csv(file.path(path.doc, "Arb_Fall_Phenology_data.csv"))
dat.2018 <- dat.npn[dat.npn$year == 2018,]
dat.2018 <- dat.2018[dat.2018$day_of_year <= 341,]
dat.npn <- dat.npn[dat.npn$year == 2019,]
dat.npn <- dat.npn[order(dat.npn$day_of_year),]
dat.npn$color.clean <- as.numeric(as.character(dat.npn$color.clean))
RandomWalk_binom = "
model{
#### Data Model
for(i in 1:n){
y[i] ~ dbern(x[time[i]])
}
#### Process Model
for(t in 2:nt){
z[t] ~ dnorm(x[t-1],tau_add)
x[t] <- min(0.999,max(0.0001,z[t]))
}
#### Priors
x[1] ~ dlnorm(x_ic,tau_ic)
tau_add ~ dgamma(a_add,r_add)
}
"
#dat.roll <- dat.roll[dat.roll$week < 48,]
data.new <- list(y = dat.npn$color.clean, n = length(dat.npn$color.clean), time = dat.npn$day_of_year-(min(dat.npn$day_of_year)-1), nt = 341-213,
a_add=100, r_add=1, x_ic = -100 , tau_ic = 1000)
j.model   <- jags.model (file = textConnection(RandomWalk_binom),
data = data.new,
n.chains = 3)
jags.out   <- coda.samples (model = j.model,
variable.names = c("x","tau_add"),
n.iter = 40000)
gelman.diag(jags.out)
#plot(jags.out)
#GBR <- gelman.plot(jags.out)
burnin = 30000                                ## determine convergence
jags.burn <- window(jags.out,start=burnin)
## remove burn-in
#plot(jags.burn)
#summary(jags.burn)## check diagnostics post burn-in
out <- as.matrix(jags.burn)
x.cols <- grep("^x",colnames(out)) ## grab all columns that start with the letter x
ci <- apply(out[,x.cols],2,quantile,c(0.025,0.5,0.975))
time <- 214:341
data_all = dat.npn[,c("day_of_year","color.clean")]
data_all = data_all[order(data_all$day_of_year),]
data_all$color.clean = as.numeric(as.character(data_all$color.clean))
data_all$day_of_year = as.numeric(as.character(data_all$day_of_year))
data_all_loess_10 <- loess(as.numeric(as.character(color.clean)) ~ as.numeric(as.character(day_of_year)), data=data_all, span=0.10) # 10% smoothing span
data_all_loess_10 <- predict(data_all_loess_10)
data_all_loess_30 <- loess(as.numeric(as.character(color.clean)) ~ as.numeric(as.character(day_of_year)), data=data_all, span=0.30) # 30% smoothing span
data_all_loess_30 <- predict(data_all_loess_30)
png(filename= file.path(path.fig, paste0("Daily_Oak_Collection_Model_CI.png")))
plot(time,ci[2,],ylim=c(0,1), xlim=c(210, 350),main = "Daily Oak Collection Model CI", ylab="Fall color")
ecoforecastR::ciEnvelope(time,ci[1,],ci[3,],col=ecoforecastR::col.alpha("lightBlue",0.75))
points(dat.npn$day_of_year, dat.npn$color.clean ,pch="+",cex=0.5)
lines(data_all_loess_10, x=data_all$day_of_year, col="red", lwd = 2)
lines(data_all_loess_30, x=data_all$day_of_year, col="blue", lwd = 2)
dev.off()
#This section is for defining a range for a 2018 hindcast
dat.2018$day_of_year <- as.numeric(as.character(dat.2018$day_of_year))
dat.2018$color.clean <- as.numeric(as.character(dat.2018$color.clean))
data_2018 <- list(y = dat.2018$color.clean, n = length(dat.2018$color.clean), time = dat.2018$day_of_year-(min(dat.2018$day_of_year)-1), nt = 341-213,
a_add=100, r_add=1, x_ic = -100, tau_ic = 1000)
#------------------------------------------------------------------------------------------#
#Here is where the 2018 forecast begins and things start getting tricky
#------------------------------------------------------------------------------------------#
#-------------------------------------#
#First is the forecast function that determines our uncertainty at each time point
#--------------------------------------#
#Number of monte Carlo iterations that will be used
Nmc = 10
#Set the Initial conditions using the parameters from your model
#IC <- rlnorm(Nmc, data$x_ic,(1/sqrt(data$tau_ic)))
#This if for 2018 hindcast testing
IC <- rlnorm(Nmc, data_2018$x_ic,(1/sqrt(data_2018$tau_ic)))
#### Forecast function
##` @param IC    Initial Conditions
##` @param Q     Process error (default = 0 for deterministic runs)
##` @param n     Size of Monte Carlo ensemble
NT = data_2018$nt
forecastx <- function(IC,Q,n=Nmc){
x <- z <- matrix(NA,n,NT)  ## storage
Xprev <- IC           ## initialize
for(t in 1:NT){
mu <- Xprev
z[,t] = rnorm(n,mu, Q)
x[,t] <- pmin(0.999,pmax(0.0001,z[,t]))
Xprev <- x[,t]                                  ## update IC
}
return(x)
}
param.mean <- apply(out,2,mean)
x.det_LOD <- forecastx(IC=mean(IC),
Q=mean((1/sqrt(out[,"tau_add"]))),  ## process error off
n=Nmc)
x.i_LOD <- forecastx(IC=IC,
Q=mean((1/sqrt(out[,"tau_add"]))),  ## process error off
n=Nmc)
s = seq(1, nrow(out), length=Nmc)
x.ip_LOD <- forecastx(IC=IC,
Q=1/sqrt(out[s,"tau_add"]),  ## process error off
n=Nmc)
det_ci_LOD <- apply(x.det_LOD,2,quantile,c(0.025,0.5,0.975))
i_ci_LOD <- apply(x.i_LOD,2,quantile,c(0.025,0.5,0.975))
ip_ci_LOD <- apply(x.ip_LOD,2,quantile,c(0.025,0.5,0.975))
#----------------------------------------------------------------------------------------------------------------------------------#
# Script by : Lucien Fitzpatrick
# Project: Living Collections Phenology Forecasting
# Purpose: To use arb weather data and phenology monitoring data to create a predicitve model of fall color intensity
#          This script is the first, most simplified, version of the model that we have
# Inputs: Clean NPN observation dataframe from 3_NPN_clean.R script
#         Daymet_clean_data from 2_Daymet_download.R
# Outputs: Dataframe that has the weather calculations for all days of interest
# Notes:
#-----------------------------------------------------------------------------------------------------------------------------------#
library(rjags)
library(coda)
library(ecoforecastR)
path.doc <- ("../data_processed/fall/")
path.fig <- ("../data_processed/fall/figures")
dat.npn <- read.csv(file.path(path.doc, "Arb_Fall_Phenology_data.csv"))
